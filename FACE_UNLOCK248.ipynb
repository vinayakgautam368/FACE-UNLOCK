{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FACE UNLOCK248.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hgS4Y1XiMo79qb4K6FUkyOvo0gclTGH2",
      "authorship_tag": "ABX9TyPSmk9PwXGq49V39Kpd9USv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayakgautam368/FACE-UNLOCK/blob/main/FACE_UNLOCK248.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_T6l18DwPpT"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from itertools import combinations\n",
        "from collections import OrderedDict\n",
        "from tqdm import tqdm\n",
        "  \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNXsYdub2kH3",
        "outputId": "5f30dd82-5091-4c33-ac04-c8c18b60799b"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T_4RReU2ozI"
      },
      "source": [
        "PATH=\"/content/drive/MyDrive/archive/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6iCiDSP450o"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path, transform=transforms.ToTensor()):\n",
        "        self.dirs = glob.glob(f'{path}*/')\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.total_images = self._get_images(self.dirs, self.transform)\n",
        "\n",
        "    def _get_images(self, dirs, transform):\n",
        "        ti = []\n",
        "        for dir in tqdm(dirs):\n",
        "            images = [transform(Image.open(image)) for image in glob.glob(f'{dir}*')]\n",
        "            ti.append(images)\n",
        "        return ti\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.dirs.__len__()\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return torch.stack(self.total_images[idx], dim=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rj7Pdk96Vxh"
      },
      "source": [
        "process = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=0.4422, std=0.1931),\n",
        "])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UEZOhXr6edD",
        "outputId": "29a02385-52be-4a5a-ef12-137ab2848797"
      },
      "source": [
        "att_dataset = CustomDataset(PATH, transform=process)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:01<00:00, 23.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sfQ1vPm6mbQ"
      },
      "source": [
        "# att_dataset[0].shape\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uILtAcvs_8KB"
      },
      "source": [
        "# _,axxr = plt.subplots(40,10, figsize=(12,60))\n",
        "# for i in range(40):\n",
        "#     for j in range(10):\n",
        "#         axxr[i][j].imshow(att_dataset[i][j].squeeze(), cmap='gray')\n",
        "# plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQQ3ln2c__-T"
      },
      "source": [
        "\n",
        "dataset = list(att_dataset)\n",
        "# for i in dataset:\n",
        "#   print(i.shape)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I4ASE44A6If"
      },
      "source": [
        "\n",
        "def triplet_loss(anchor, positive, negative, margin=1):\n",
        "    pos_dist = (anchor - positive).pow(2).sum(-1) #.pow(.5)\n",
        "    neg_dist = (anchor - negative).pow(2).sum(-1) #.pow(.5)\n",
        "    loss = F.relu(pos_dist - neg_dist + margin)\n",
        "    return loss.mean()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cBmCdW9FGnP"
      },
      "source": [
        "For the triplets we select one class as anchor class fromehich we select one random image from same class as positive,and for the negative we select 1 random image from each (n-1)classes ,here we have 40 classes so foe each anchor we have 39 negatives(1 from each 39 classes),and each class contain 10 images so for each class we have (39)mul(10)=390 tripets ,so for 40 classes we have (390)mul(40)=15600 triplets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKDf8FS0CbbX"
      },
      "source": [
        "def get_random_triplets(embeddings,  targets=None) -> torch.Tensor:\n",
        "\n",
        "\n",
        "    triplets = []\n",
        "    for i, embedding in enumerate(embeddings):\n",
        "        temp = embeddings.pop(i)\n",
        "\n",
        "        for anchor in embedding:\n",
        "            positive = random.choice(embedding)\n",
        "\n",
        "            for negatives in embeddings:\n",
        "                negative = random.choice(negatives)\n",
        "\n",
        "                triplets.append(torch.stack([anchor, positive, negative], dim=0))\n",
        "\n",
        "        embeddings.insert(i, temp)\n",
        "\n",
        "    return torch.stack(triplets, dim=0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFRN0AdfC84E"
      },
      "source": [
        "def dist(enc1,enc2):\n",
        "    return (enc1 - enc2).pow(2).sum(-1).pow(.5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P78hVfytDBf0"
      },
      "source": [
        "\n",
        "# triplets = get_random_triplets(dataset[:5])\n",
        "# print(triplets.shape)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL5ZLE-zDJNG"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcVgRQnyDU8u"
      },
      "source": [
        "# _,axxr = plt.subplots(60,3, figsize=(12,120))\n",
        "# for i in range(60):\n",
        "#     for j in range(3):\n",
        "#         axxr[i][j].imshow(triplets[i][j].squeeze(), cmap='gray')\n",
        "# plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "# # ref : https://stackoverflow.com/questions/25124143/matplotlib-subplots-get-rid-of-tick-labels-altogether\n",
        "# plt.show()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-7wLJlgDYr5",
        "outputId": "bc68350f-7ac1-4010-e5a6-252910b1d977"
      },
      "source": [
        "train = dataset[0:30]\n",
        "len(train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfjbq36fDmrZ"
      },
      "source": [
        "# test = dataset[30:]\n",
        "# len(test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IlPPTNCbCzc"
      },
      "source": [
        "class BasicBlock(nn.Module):     # THIS IS THE FIRST CONVOLUTION BLOCK\n",
        "  def __init__(self,inplanes,planes,stride=1,downsample=None):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(inplanes,planes,kernel_size=3,padding=1,stride=stride,bias=False)\n",
        "    self.bn1=nn.BatchNorm2d(planes)\n",
        "    self.relu=nn.ReLU(inplace=True)\n",
        " \n",
        "    self.conv2=nn.Conv2d(planes,planes,kernel_size=3,padding=1,stride=1,bias=False)\n",
        "    self.bn2=nn.BatchNorm2d(planes)\n",
        "    self.downsample=downsample\n",
        "    self.stride=stride\n",
        " \n",
        "  def forward(self,x):\n",
        " \n",
        "    identity=x\n",
        " \n",
        "    out=self.conv1(x)\n",
        "    out=self.bn1(out)\n",
        "    out=self.relu(out)\n",
        " \n",
        "    out=self.conv2(out)\n",
        "    out=self.bn2(out)\n",
        " \n",
        "    if self.downsample is not None:\n",
        "      identity=self.downsample(x)\n",
        " \n",
        "    out+=identity\n",
        "    out=self.relu(out)\n",
        "      \n",
        " \n",
        "    return out"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU9k6OVQbEGs"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self,block,numbers,classes=128):\n",
        "    super().__init__()\n",
        " \n",
        "    #this is first simple conv block\n",
        "    self.inplanes=64\n",
        "    self.conv1=nn.Conv2d(1,self.inplanes,kernel_size=7,stride=2,padding=3,bias=False)    \n",
        "    self.bn1=nn.BatchNorm2d(self.inplanes)\n",
        "    self.relu=nn.ReLU(inplace=True)\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)       #gives shape  (2,64,56,56)\n",
        " \n",
        "    # now 4 layers\n",
        "    self.layer1=self._make_layer(block,64,numbers[0])\n",
        "    self.layer2=self._make_layer(block,128,numbers[1],stride=2)\n",
        "    self.layer3=self._make_layer(block,256,numbers[2],stride=2)\n",
        "    self.layer4=self._make_layer(block,512,numbers[3],stride=2)\n",
        " \n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc=nn.Linear(512,classes)\n",
        " \n",
        "  def _make_layer(self,block,planes,blocks,stride=1):\n",
        "    downsample=None\n",
        " \n",
        "    if stride!=1 or self.inplanes!=planes:\n",
        "      downsample=nn.Sequential(nn.Conv2d(self.inplanes,planes,1,stride,bias=False),nn.BatchNorm2d(planes))\n",
        "    layers=[]\n",
        " \n",
        "    layers.append(block(self.inplanes,planes,stride,downsample))\n",
        "    self.inplanes=planes\n",
        " \n",
        "    for j in range(1,blocks):\n",
        "      layers.append(block(self.inplanes,planes))\n",
        "    return nn.Sequential(*layers)\n",
        " \n",
        " \n",
        "  def semi_forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    x=self.bn1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.maxpool(x)\n",
        "    # print(x.shape)\n",
        " \n",
        "    x=self.layer1(x)\n",
        "    x=self.layer2(x)\n",
        "    x=self.layer3(x)\n",
        "    x=self.layer4(x)\n",
        " \n",
        "    x=self.avgpool(x)\n",
        "    x=torch.flatten(x,1)\n",
        " \n",
        "    x=self.fc(x)\n",
        " \n",
        " \n",
        "    return x\n",
        "\n",
        "\n",
        "  def forward(self,triplet):\n",
        "    anc = self.semi_forward(triplet[:,0,...])\n",
        "    pos = self.semi_forward(triplet[:,1,...])\n",
        "    neg = self.semi_forward(triplet[:,2,...])\n",
        "    return [anc, pos, neg]    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bepsT-OF9Fx"
      },
      "source": [
        "numbers=[2,2,2,2]\n",
        "\n",
        "resnet18 = ResNet(BasicBlock,numbers)\n",
        "\n",
        "# t = torch.rand(10,1,224,224)\n",
        "# print('rand', t.shape)\n",
        "# t = resnet18.semi_forward(t)\n",
        "# print('Inbuilt', t.shape)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SlNyHk6Ej-c"
      },
      "source": [
        "# t = torch.rand(100,3,1,224,224)\n",
        "# print('rand', t.shape)\n",
        "# t = resnet18(t)\n",
        "# print('resnet18', t[0].shape, t[1].shape, t[2].shape)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUAY7Ed0Ew3X"
      },
      "source": [
        "\n",
        "def Train(model, batch, loss_fn, optimizer, cost):\n",
        "    model.train()\n",
        "\n",
        "    apn = model(batch)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fn(*apn)\n",
        "    cost.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return cost[-1]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D8R9x7gHMh8"
      },
      "source": [
        "\n",
        "def Evaluate(model, batch):\n",
        "    model.eval()\n",
        "    def dist(enc1,enc2):\n",
        "        return (enc1 - enc2).pow(2).sum(-1).pow(.5)\n",
        "    with torch.no_grad():\n",
        "        sample = torch.cat([model.semi_forward(imgs[0].unsqueeze(0)) for imgs in batch])\n",
        "        total_enc = [model.semi_forward(img) for img in batch]\n",
        "        pred = [torch.stack([dist(enc,sample).argmin() for enc in total_enc[i]]) for i in range(len(total_enc))]\n",
        "        acc = sum([(pred[i] == i).sum() for i in range(len(total_enc))])\n",
        "        del total_enc\n",
        "    return (acc.item() / (len(batch) * 10) )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE0WVqPZH0gC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2d0385-5314-4b49-e4a6-71b35742f395"
      },
      "source": [
        "\n",
        "torch.set_grad_enabled(True)\n",
        "resnet18.train(True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=128, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_rDzSLFvRO"
      },
      "source": [
        "learning_rate = 0.0001\n",
        "optimizer = optim.Adam(resnet18.parameters(), lr = learning_rate)\n",
        "torch_triplet_loss = nn.TripletMarginLoss()\n",
        "if torch.cuda.is_available():\n",
        "    resnet18 = resnet18.cuda()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6uUo4zoqHGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a262e8f9-2afc-4775-fd7e-9603291d374d"
      },
      "source": [
        "cost = [float('inf')]\n",
        "train_acc = [0]\n",
        "test_acc = [0]\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    triplets = get_random_triplets(train)\n",
        "    loader = DataLoader(triplets, batch_size=100)\n",
        "    for i,batch in enumerate(loader):\n",
        "\n",
        "        loss = Train(resnet18, batch, triplet_loss, optimizer, cost)\n",
        "        \n",
        "        # pred = Evaluate(resnet18, train)\n",
        "        # acc1 = ( (pred == torch.arange(len(pred)).reshape(-1,1)).sum() / (len(pred)*10) ).item()\n",
        "        # train_acc.append(acc1)\n",
        "\n",
        "        # pred = Evaluate(resnet18, test)\n",
        "        # acc2 = ( (pred == torch.arange(len(pred)).reshape(-1,1)).sum() / (len(pred)*10) ).item()\n",
        "        # test_acc.append(acc2)\n",
        "\n",
        "        if (i+1)%20==0 :\n",
        "            # print(f'Epoch:[{epoch+1}/{epochs}], Step:[{i+1}/87]', 'Cost : {:.2f}, Train Acc: {:.2f}, Test Acc: {:.2f}'.format(loss, acc1, acc2))\n",
        "            print(f'Epoch:[{epoch+1}/{epochs}], Step:[{i+1}/87]', 'Cost : {:.2f}'.format(loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:[1/5], Step:[20/87] Cost : 0.06\n",
            "Epoch:[1/5], Step:[40/87] Cost : 0.04\n",
            "Epoch:[1/5], Step:[60/87] Cost : 0.07\n",
            "Epoch:[1/5], Step:[80/87] Cost : 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNdJWKEmGQ0-"
      },
      "source": [
        "# cost = []\n",
        "# train_acc = []\n",
        "# test_acc = []\n",
        "# total_acc = []\n",
        "# epochs = 10\n",
        "# for epoch in range(epochs):\n",
        "\n",
        "#     triplets = get_random_triplets(train)\n",
        "#     loader = DataLoader(triplets, batch_size=100)\n",
        "#     for i,batch in enumerate(loader):\n",
        "\n",
        "#         apn = resnet18(batch)\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "#         loss = triplet_loss(*apn)\n",
        "#         cost.append(loss.item())\n",
        "\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         ####\n",
        "#         with torch.no_grad():\n",
        "#             resnet18.train(False)\n",
        "#             sample = torch.cat([resnet18.semi_forward(att_dataset[i][0].unsqueeze(0)) for i in range(40)])\n",
        "#             total_enc = [resnet18.semi_forward(img) for img in dataset]\n",
        "#             pred = [torch.stack([dist(enc,sample).argmin() for enc in total_enc[i]]) for i in range(40)]\n",
        "#             acc1 = sum([(pred[i] == i).sum() for i in range(0,30)])\n",
        "#             acc2 = sum([(pred[i] == i).sum() for i in range(30,40)])\n",
        "#             train_acc.append(acc1.item()  / 300)\n",
        "#             test_acc.append(acc2.item() / 100)\n",
        "#             total_acc.append((acc1.item() + acc2.item()) / 400 )\n",
        "#             del total_enc\n",
        "#             resnet18.train(True)\n",
        "#         ####\n",
        "\n",
        "#         if (i+1)%20==0 :\n",
        "#             print(f'Epoch:[{epoch+1}/{epochs}], Step:[{i+1}/87]', 'Cost : {:.2f}, Train Acc: {:.2f}, Test Acc: {:.2f}'.format(loss.item(), acc1.item()/3, acc2.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMuymhAuGW3m"
      },
      "source": [
        "a=[[1,2,3],[12,3],[3,4,4],4]\n",
        "for i,j in enumerate(a):\n",
        "  a.pop(i)\n",
        "  print(i,j)\n",
        "  print(a)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYD6DWyzt_D9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}